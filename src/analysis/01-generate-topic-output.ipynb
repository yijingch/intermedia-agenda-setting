{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/yijingch/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/yijingch/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/yijingch/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/yijingch/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/yijingch/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "nltk.download(\"omw-1.4\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "import yaml\n",
    "with open(\"../../src/configs.yml\", \"r\") as configs:\n",
    "    configs = yaml.safe_load(configs)\n",
    "\n",
    "from src.utils.data_loader import Headlines\n",
    "\n",
    "DATAPATH = configs[\"DATAPATH\"]\n",
    "ROOTPATH = configs[\"ROOTPATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.dict_configuration import dictionary2016, dictionary2020\n",
    "\n",
    "year = 2020\n",
    "if year == 2016:\n",
    "    cand1 = \"trump\"\n",
    "    cand2 = \"clinton\"\n",
    "    dictionary = dictionary2016\n",
    "else:\n",
    "    cand1 = \"biden\"\n",
    "    cand2 = \"trump\"\n",
    "    dictionary = dictionary2020\n",
    "\n",
    "dictionary.construct_overlap_matrix()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading headlines...\n",
      "Cleaning headlines...\n",
      "cleaning...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading headlines...\")\n",
    "headlines = Headlines(ROOTPATH + \"data/\", year=year)\n",
    "print(\"Cleaning headlines...\")\n",
    "headlines.clean(lemmatize=False, stemming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.dict_based_topics import DictBasedTopicModel\n",
    "\n",
    "save_output = True\n",
    "drop_no_topic = True\n",
    "topvec_out_cache_fpath = ROOTPATH+\"output/cache-topvec-min2\"\n",
    "wordvec_out_cache_fpath = ROOTPATH+\"output/cache-wordvec-min2\"\n",
    "\n",
    "if not os.path.exists(topvec_out_cache_fpath):\n",
    "    os.mkdir(topvec_out_cache_fpath)\n",
    "    print(\"New output folder created for topvecs!\")\n",
    "\n",
    "if not os.path.exists(wordvec_out_cache_fpath):\n",
    "    os.mkdir(wordvec_out_cache_fpath)\n",
    "    print(\"New output folder created for wordvecs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing headlines...\n",
      "- Building wordvec...\n",
      "Finished counting topic keywords: trump2016\n",
      "Finished counting topic keywords: clinton2016\n",
      "Rate of coverage for trump2016: 0.8463640954424946\n",
      "Rate of coverage for clinton2016: 0.8728246235551778\n",
      "Now we can save wordvecs as well! [new!]...\n",
      "- Building topvec...\n",
      "Finished computing topic vector: trump2016\n",
      "Finished computing topic vector: clinton2016\n"
     ]
    }
   ],
   "source": [
    "# runtime:\n",
    "# 111 mins -- for 2020\n",
    "# 115 mins -- for 2016\n",
    "\n",
    "print(\"Analyzing headlines...\")\n",
    "headlinetopics = DictBasedTopicModel(dictionary=dictionary, text_input=headlines, text_type=\"headline\")\n",
    "print(\"- Building wordvec...\")\n",
    "headlinetopics.build_wordvec_df(drop_no_topic=drop_no_topic, save_output=save_output, output_cache_fpath=wordvec_out_cache_fpath)\n",
    "print(\"- Building topvec...\")\n",
    "headlinetopics.build_topvec_df(save_output=save_output, output_cache_fpath=topvec_out_cache_fpath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing headlines...\n",
    "# - Building wordvec...\n",
    "# Finished counting topic keywords: trump2016\n",
    "# Finished counting topic keywords: clinton2016\n",
    "# Rate of coverage for trump2016: 0.8463640954424946\n",
    "# Rate of coverage for clinton2016: 0.8728246235551778\n",
    "# Now we can save wordvecs as well! [new!]...\n",
    "# - Building topvec...\n",
    "# Finished computing topic vector: trump2016\n",
    "# Finished computing topic vector: clinton2016\n",
    "\n",
    "\n",
    "# Analyzing headlines...\n",
    "# - Building wordvec...\n",
    "# Finished counting topic keywords: biden2020\n",
    "# Finished counting topic keywords: trump2020\n",
    "# Rate of coverage for biden2020: 0.876492214225894\n",
    "# Rate of coverage for trump2020: 0.8975569546768105\n",
    "# Now we can save wordvecs as well! [new!]...\n",
    "# - Building topvec...\n",
    "# Finished computing topic vector: biden2020\n",
    "# Finished computing topic vector: trump2020"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ceren')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a9c9f468449d0a4136dac77d2c71b6e07192647cd6ae4c2753d8b2962f50d5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
